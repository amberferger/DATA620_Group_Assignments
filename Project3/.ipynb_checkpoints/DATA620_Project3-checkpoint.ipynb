{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUNY Data 620 - Web Analytics, Summer 2020  \n",
    "**Group Project 3**   \n",
    "**Prof:** Alain Ledon  \n",
    "**Members:** Misha Kollontai, Amber Ferger, Zach Alexander, Subhalaxmi Rout  \n",
    "  \n",
    "**YouTube Link**: https://www.youtube.com/watch?v=a3oDaz4SHSY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "Using any of the three classifiers described in chapter 6 of Natural Language Processing with Python,\n",
    "and any features you can think of, build the best name gender classifier you can. \n",
    "\n",
    "Begin by splitting the Names Corpus into three subsets: 500 words for the test set, 500 words for the devtest set, and the remaining 6900 words for the training set. Then, starting with the example name gender classifier, make incremental improvements. Use the dev-test set to check your progress. Once you are satisfied with your classifier, check its final performance on the test set.\n",
    "\n",
    "\n",
    "How does the performance on the test set compare to the performance on the dev-test set? Is this what\n",
    "you'd expect? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "import math\n",
    "from itertools import repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "The *names* corpus in the nltk package contains the names and genders of 7,944 individuals. First, we will compile a list of all names with their gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2943 male names in the dataset.\n",
      "There are 5001 female names in the dataset.\n"
     ]
    }
   ],
   "source": [
    "males = [(name, 'male') for name in names.words('male.txt')]\n",
    "numMales = len(males)\n",
    "females = [(name, 'female') for name in names.words('female.txt')]\n",
    "numFemales = len(females)\n",
    "\n",
    "print(f'There are {numMales} male names in the dataset.')\n",
    "print(f'There are {numFemales} female names in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine the lists and shuffle the data so that all names of the same gender are not together. We can confirm that the names are shuffled by looking at the genders of the first 5 individuals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 names in the dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Cordelie', 'female'),\n",
       " ('Peggie', 'female'),\n",
       " ('Solange', 'female'),\n",
       " ('Rana', 'female'),\n",
       " ('Jessy', 'female')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(123)\n",
    "allNames = males + females\n",
    "random.shuffle(allNames)\n",
    "\n",
    "print('First 5 names in the dataset:')\n",
    "allNames[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Features\n",
    "Next, we'll define a function to create features for our names. The initial features will include:\n",
    "* **last_letter**: The last letter of the given name.\n",
    "* **first_letter**: The first letter of the given name. \n",
    "* **name_length**: The length of the given name.\n",
    "* **num_vowels**: The number of vowels in the given name.\n",
    "* **num_consonants**: The number of consonants in the given name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)  \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split\n",
    "Now that we've defined our feature function, we can run it on our dataset and split it into training, testing, and dev testing sets. \n",
    "* **Training Set**: This data will be used to train our classifiers and fit the models.\n",
    "* **Dev Test Set**: This data will be used to predict the gender (male or female). It will provide an unbiased evaluation of a model fit on the training dataset. We can use the results of the development set to tune our model. \n",
    "* **Test Set**: This data will be used to compute the accuracy of the final model. Since the model has never seen this data, it will provide an unbiased evaluation of the clasifier.\n",
    "\n",
    "The splits will be in the format of ({features}, gender). We will store the names and genders of the individuals in separate lists for each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num records - train set:  6944\n",
      "Num records - dev test set:  500\n",
      "Num records - test set:  500\n"
     ]
    }
   ],
   "source": [
    "def tts(featureFunc, nameList):\n",
    "    featureSet = [(featureFunc(n),g) for (n,g) in nameList]\n",
    "    test_set, devtest_set, train_set = featureSet[0:500], featureSet[500:1000], featureSet[1000:] \n",
    "    tsName = nameList[0:500]\n",
    "    dtName = nameList[500:1000]\n",
    "    tName = nameList[1000:]\n",
    "    \n",
    "    return test_set, devtest_set, train_set, tsName, dtName, tName\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features, allNames)\n",
    "\n",
    "print('Num records - train set: ', len(train_set))\n",
    "print('Num records - dev test set: ', len(devtest_set))\n",
    "print('Num records - test set: ', len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Classifier - Naive Bayes Classifier\n",
    "Now that we've split our data into training, development, and test sets, we can create a **Naive Bayes Classifier** to predict the gender of the names. In this type of model, each feature gets a say in determining which label should be assigned to a given input value. The prior probability is calculated for each label (male, female), and the contribution from each feature is combined with this probability to arrive at a likelihood estimate for each label.\n",
    "\n",
    "We will measure the accuracy of the model (the percentage of names the classifier predicts correctly) using the development test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.782\n"
     ]
    }
   ],
   "source": [
    "nbClass = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass, devtest_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also take a look at the most important features used for predicting the gender. For each feature, this tells us the ratio of occurences for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     33.3 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.2 : 1.0\n",
      "             last_letter = 'p'              male : female =     18.6 : 1.0\n",
      "             last_letter = 'f'              male : female =     15.2 : 1.0\n",
      "             last_letter = 'v'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'd'              male : female =      9.8 : 1.0\n",
      "             last_letter = 'm'              male : female =      9.2 : 1.0\n",
      "             last_letter = 'o'              male : female =      8.0 : 1.0\n",
      "             last_letter = 'w'              male : female =      8.0 : 1.0\n",
      "             last_letter = 'r'              male : female =      6.7 : 1.0\n",
      "            first_letter = 'w'              male : female =      4.6 : 1.0\n",
      "              num_vowels = 5              female : male   =      4.5 : 1.0\n",
      "             last_letter = 'b'              male : female =      4.4 : 1.0\n",
      "             last_letter = 's'              male : female =      4.3 : 1.0\n",
      "             last_letter = 'g'              male : female =      4.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nbClass.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the last letter and number of vowels in the names appear to be the driving factors. \n",
    "\n",
    "We can also generate a list of errors to see which names we've classified improperly. This will help us identify what additional features we should add to make the classification more accurate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of errors: 109\n"
     ]
    }
   ],
   "source": [
    "def pred_calc(nameList, featureFunc, nbClass):\n",
    "    preds = []\n",
    "    errors = []\n",
    "    for (name,actual) in nameList:\n",
    "        guess = nbClass.classify(featureFunc(name))\n",
    "        preds.append((actual,guess,name))\n",
    "        if guess != actual:\n",
    "            errors.append((actual, guess, name))\n",
    "    \n",
    "    return preds, errors\n",
    "\n",
    "preds, errors = pred_calc(dtName, gender_features, nbClass)\n",
    "print('Number of errors:', len(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we sort the errors by the last two characters of the first name, we can see that some combinations occur more frequently in males than females and vice versa. For example, the letters *ie* appear more often in male names and then letters *ly* appear more often in female names. Let's update our feature set to take this into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('female', 'male', 'Em'),\n",
       " ('female', 'male', 'Talyah'),\n",
       " ('female', 'male', 'Shirah'),\n",
       " ('male', 'female', 'Donal'),\n",
       " ('female', 'male', 'Sam'),\n",
       " ('male', 'female', 'Fabian'),\n",
       " ('female', 'male', 'Sean'),\n",
       " ('male', 'female', 'Coleman'),\n",
       " ('male', 'female', 'Christian'),\n",
       " ('male', 'female', 'Adrian')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(errors, key=lambda x: x[-1][-2:])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Set Revamp\n",
    "\n",
    "Now that we have a baseline for comparison, let's add some features to our dataset. For each iteration with new features, we will recreate our train, test, and dev test splits and run the Naive Bayes Classifer on the data.\n",
    "\n",
    "#### Model 2\n",
    "Model 2 will include 3 additional features:\n",
    "* **last_two_letters**: Last 2 letters of the name.\n",
    "* **first_two_letters**: First 2 letters of the name. \n",
    "* **dbl_ltrs**: Presence of double letters (ex: *tt*) in a name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.82\n",
      "Number of errors: 90\n"
     ]
    }
   ],
   "source": [
    "def gender_features2(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "    \n",
    "    # add in feature for last 2 letters of name\n",
    "    features['last_two_letters'] = name[-2:]\n",
    "    \n",
    "    # add in feature for first 2 letters of name\n",
    "    features['first_two_letters'] = name[:2]\n",
    "    \n",
    "    # presence of double letters:\n",
    "    def find_dbl_ltrs(x):\n",
    "        groups = groupby(name)\n",
    "        result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "        return (len([x[1] for x in result if x[1]>1]))\n",
    "    features['dbl_ltrs'] = find_dbl_ltrs(name)\n",
    "\n",
    "    return features\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features2, allNames)\n",
    "nbClass2 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass2, devtest_set))\n",
    "\n",
    "preds2, errors2 = pred_calc(dtName, gender_features2, nbClass2)\n",
    "print('Number of errors:', len(errors2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our accuracy went up to **82%**! Let's try again with some additional features.\n",
    "\n",
    "#### Model 3\n",
    "Our third model will include the addition of **Bouba and Kiki Vowels/Consonants**. Sidhu and Pexman (1) discovered a relationship of Bouba with female first names and Kiki with male first names. We will use a modified version of their findings and define the following new features: \n",
    "* **num_bouba_cons**: Count of the letters *b*, *l*, *m*, and *n*. *(Female names tend to have more of these)*\n",
    "* **num_bouba_vowels**: Count of the letters *u* and *o*. *(Female names tend to have more of these)*\n",
    "* **num_kiki_cons**: Count of the letters *k*, *p*, and *t*. *(Male names tend to have more of these)*\n",
    "* **num_kiki_vowels**: Count of the letters *i* and *e*. *(Male names tend to have more of these)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.81\n",
      "Number of errors: 95\n"
     ]
    }
   ],
   "source": [
    "# https://arxiv.org/pdf/1606.05467.pdf\n",
    "\n",
    "def gender_features3(name):\n",
    "    name = name.lower()\n",
    "    features = {}\n",
    "    features['last_letter'] = name[-1]\n",
    "    features['first_letter'] = name[0]\n",
    "    features['name_length'] = len(name)    \n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    vowelLength = len([i for i in name if i in vowels])\n",
    "    features['num_vowels'] = vowelLength\n",
    "    features['num_consonants'] = len(name) - vowelLength\n",
    "    \n",
    "    # add in feature for last 2 letters of name\n",
    "    features['last_two_letters'] = name[-2:]\n",
    "    \n",
    "    # add in feature for first 2 letters of name\n",
    "    features['first_two_letters'] = name[:2]\n",
    "    \n",
    "    # presence of double letters:\n",
    "    def find_dbl_ltrs(x):\n",
    "        groups = groupby(name)\n",
    "        result = [(label, sum(1 for _ in group)) for label, group in groups]\n",
    "        return (len([x[1] for x in result if x[1]>1]))\n",
    "    features['dbl_ltrs'] = find_dbl_ltrs(name)\n",
    "    \n",
    "    # add in bouba & kiki counts\n",
    "    boubaCons = ['b', 'l', 'm', 'n']\n",
    "    boubaVowels = ['u', 'o']\n",
    "    kikiCons = ['k', 'p', 't']\n",
    "    kikiVowels = ['i', 'e']\n",
    "    \n",
    "    bcLength = len([i for i in name if i in boubaCons])\n",
    "    bvLength = len([i for i in name if i in boubaVowels])\n",
    "    kcLength = len([i for i in name if i in kikiCons])\n",
    "    kvLength = len([i for i in name if i in kikiVowels])\n",
    "\n",
    "    features['num_bouba_cons'] = bcLength\n",
    "    features['num_bouba_vowels'] = bvLength\n",
    "    features['num_kiki_cons'] = kcLength\n",
    "    features['num_kiki_vowels'] = kvLength\n",
    "\n",
    "    return features\n",
    "\n",
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "nbClass3 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy: ', nltk.classify.accuracy(nbClass3, devtest_set))\n",
    "\n",
    "preds3, errors3 = pred_calc(dtName, gender_features3, nbClass3)\n",
    "print('Number of errors:', len(errors3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the addition of these features actually *decreased* the accuracy of predictions on the development set. This could be because our training data is **overfit** to the features, which brings up an important point - more features does not always mean a better model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "#### Overall Accuracy\n",
    "We can now evaluate the models on our **test set**. First, we'll look at the overall accuracy of each of our subsequent models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DEV_ACCURACY</th>\n",
       "      <th>TEST_ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Third</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MODEL  DEV_ACCURACY  TEST_ACCURACY\n",
       "0   First         0.782          0.772\n",
       "1  Second         0.820          0.800\n",
       "2   Third         0.810          0.802"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['First', nltk.classify.accuracy(nbClass, devtest_set), nltk.classify.accuracy(nbClass, test_set)], \n",
    "             ['Second', nltk.classify.accuracy(nbClass2, devtest_set), nltk.classify.accuracy(nbClass2, test_set)], \n",
    "             ['Third', nltk.classify.accuracy(nbClass3, devtest_set), nltk.classify.accuracy(nbClass3, test_set)]],\n",
    "            columns = ['MODEL', 'DEV_ACCURACY', 'TEST_ACCURACY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy on the development set increases from the first model to the second model, and then decreases from the second model to the third model. However, it is interesting to note that the accuracy on the test set actually increases from the first model to the third! \n",
    "\n",
    "When looking at each model, we also notice that the accuracy on the test set is lower than on the development set. This is expected, as we tweaked our feature set based on the results of the development set and the test set contains data that the model has never seen before.\n",
    "\n",
    "**Based on these results, we will use model 3 as our final model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Specific Accuracies\n",
    "Now that we've looked at the overall accuracy, let's take a look at the male and female specific accuracies. We'll create a function that includes a break down the results of our final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender-specific accuracy function\n",
    "def summ_table(allNames, tsPred):\n",
    "    tag = [name for name in tsPred if [name for (name, tag) in allNames]]\n",
    "    perform = []\n",
    "    for i in tsPred:\n",
    "        if (i[0] == 'male') & (i[1] == 'male'):\n",
    "            perform.append('correct male')\n",
    "        elif (i[0] == 'female') & (i[1] == 'female'):\n",
    "            perform.append('correct female')\n",
    "        elif (i[0] == 'male') & (i[1] == 'female'):\n",
    "            perform.append('incorrect male')\n",
    "        else:\n",
    "            perform.append('incorrect female')\n",
    "    correct_male = perform.count('correct male')\n",
    "    correct_female = perform.count('correct female')\n",
    "    incorrect_female = perform.count('incorrect female')\n",
    "    incorrect_male = perform.count('incorrect male')\n",
    "    \n",
    "    performance_table_pct = pd.DataFrame([['Females', \"{:.0%}\".format(correct_female / (correct_female + incorrect_female)), \"{:.0%}\".format(incorrect_female / (correct_female + incorrect_female))],\n",
    "             ['Males', \"{:.0%}\".format(correct_male / (correct_male + incorrect_male)), \"{:.0%}\".format(incorrect_male / (correct_male + incorrect_male))]],\n",
    "            columns = ['Gender', 'Percent Correct', 'Percent Incorrect'])\n",
    "    performance_table_pct.style.hide_index()\n",
    "    \n",
    "    return performance_table_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Percent Correct</th>\n",
       "      <th>Percent Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Females</td>\n",
       "      <td>83%</td>\n",
       "      <td>17%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Males</td>\n",
       "      <td>76%</td>\n",
       "      <td>24%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Percent Correct Percent Incorrect\n",
       "0  Females             83%               17%\n",
       "1    Males             76%               24%"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsPred, tsErrors = pred_calc(tsName, gender_features3, nbClass3)\n",
    "performance_table_pct = summ_table(allNames, tsPred)\n",
    "performance_table_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in our final model, the females are predicted with a higher accuracy than the males! This is likely because the dataset is skewed in favor of female names (63% female / 37% male). In order to see how much the greater accuracy for female names was driven by the imbalance within the dataset, we will balance the set using two different approaches: **Undersampling** and **Oversampling**. We will re-evaluate our model after adjusting the training data - once by removing the extra female names (undersampling) and once by copying in repeats of male names to balance out the number of female names (oversampling). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balancing the Training Set\n",
    "\n",
    "We will define a function that takes the training set, the names associated with the training set, and a 0 or 1 depending on whether an undersampling or an oversampling is preferred. Once our balanced data is created, we will re-create the model and look at the overall and gender-specific accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'over' input below signifies whether the user wants to undersample or oversample the dataset (default undersample)\n",
    "def balance_train(train_set, tName, under = 1):\n",
    "    gender = []\n",
    "    for name,g in tName:\n",
    "        if g == \"female\":\n",
    "            gender.append(1)\n",
    "        else:\n",
    "            gender.append(0)\n",
    "    n_female = sum(gender)\n",
    "    n_male = len(gender) - n_female\n",
    "    if n_female == n_male:\n",
    "        return train_set, tName\n",
    "    elif n_female > n_male:\n",
    "        more = \"F\"\n",
    "        delta = n_female - n_male\n",
    "    else:\n",
    "        more = \"M\"\n",
    "        delta = n_male - n_female\n",
    "    \n",
    "    idx_males = []\n",
    "    idx_males = [i for i, val in enumerate(tName) if val[1] == \"male\"]\n",
    "    idx_females = []\n",
    "    idx_females = [i for i, val in enumerate(tName) if val[1] == \"female\"]\n",
    "    \n",
    "    remove = []\n",
    "    copy = []\n",
    "    if more == \"F\":\n",
    "        remove = idx_females\n",
    "        remove = remove[-delta:]\n",
    "        copy = idx_males\n",
    "    elif more == \"M\":\n",
    "        remove = idx_males\n",
    "        remove = remove[-delta:]\n",
    "        copy = idx_females\n",
    "    \n",
    "    if under == 1:\n",
    "        for index in reversed(remove):\n",
    "            del tName[index]\n",
    "            del train_set[index]\n",
    "    elif under == 0:\n",
    "        for i in range(0,delta):\n",
    "            tName.append(tName[copy[i]])\n",
    "            train_set.append(train_set[copy[i]])\n",
    "    return train_set, tName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of undersampling the female set within the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Downsampling:  0.796\n",
      "Number of errors - Downsampling: 102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Percent Correct</th>\n",
       "      <th>Percent Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Females</td>\n",
       "      <td>78%</td>\n",
       "      <td>22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Males</td>\n",
       "      <td>81%</td>\n",
       "      <td>19%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Percent Correct Percent Incorrect\n",
       "0  Females             78%               22%\n",
       "1    Males             81%               19%"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "train_set, tName = balance_train(train_set, tName,1)\n",
    "\n",
    "nbClass4 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy - Downsampling: ', nltk.classify.accuracy(nbClass4, devtest_set))\n",
    "\n",
    "preds4, errors4 = pred_calc(dtName, gender_features3, nbClass4)\n",
    "print('Number of errors - Downsampling:', len(errors4))\n",
    "\n",
    "tsPred4, tsError4 = pred_calc(tsName, gender_features3,nbClass4)\n",
    "performance_table_pct = summ_table(allNames, tsPred4)\n",
    "performance_table_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are certainly interesting - by **undersampling** the female set, we see that the overall accuracy remains about the same (~80%), but the gender-specific accuracies change! We now see that the males are being predicted at a higher rate than the females!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effect of oversampling the male set within the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Oversampling:  0.798\n",
      "Number of errors - Oversampling: 101\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Percent Correct</th>\n",
       "      <th>Percent Incorrect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Females</td>\n",
       "      <td>78%</td>\n",
       "      <td>22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Males</td>\n",
       "      <td>82%</td>\n",
       "      <td>18%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Gender Percent Correct Percent Incorrect\n",
       "0  Females             78%               22%\n",
       "1    Males             82%               18%"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "train_set, tName = balance_train(train_set, tName, 0)\n",
    "\n",
    "nbClass5 = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print('Accuracy - Oversampling: ', nltk.classify.accuracy(nbClass5, devtest_set))\n",
    "\n",
    "preds5, errors5 = pred_calc(dtName, gender_features3, nbClass5)\n",
    "print('Number of errors - Oversampling:', len(errors5))\n",
    "\n",
    "tsPred5, tsError5 = pred_calc(tsName, gender_features3,nbClass5)\n",
    "summ_table(allNames, tsPred5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we see that the overall accuracy remains about the same. The gender-specific accuracies are more balanced! Ultimately, since we'd like to predict male and female names at a similar accuracy, undersampling and oversampling help to create a more balanced model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impact of original random_seed to split the data\n",
    "\n",
    "The names that make their way into the training set will obviously have an impact on how accurate a predictor model is. Below are a few result tables showing the difference in accuracy based on different initial train-test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_correct(allNames, tsPred):\n",
    "    tag = [name for name in tsPred if [name for (name, tag) in allNames]]\n",
    "    perform = []\n",
    "    for i in tsPred:\n",
    "        if (i[0] == 'male') & (i[1] == 'male'):\n",
    "            perform.append('correct male')\n",
    "        elif (i[0] == 'female') & (i[1] == 'female'):\n",
    "            perform.append('correct female')\n",
    "        elif (i[0] == 'male') & (i[1] == 'female'):\n",
    "            perform.append('incorrect male')\n",
    "        else:\n",
    "            perform.append('incorrect female')\n",
    "            \n",
    "    correct_male = perform.count('correct male')\n",
    "    correct_female = perform.count('correct female')\n",
    "    incorrect_female = perform.count('incorrect female')\n",
    "    incorrect_male = perform.count('incorrect male')\n",
    "    \n",
    "    female_pct_corr = correct_female / (correct_female + incorrect_female)\n",
    "    male_pct_corr = correct_male / (correct_male + incorrect_male)\n",
    "    \n",
    "    return female_pct_corr , male_pct_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8d\" ><thead>    <tr>        <th class=\"blank\" ></th>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Normal</th>        <th class=\"col_heading level0 col1\" >Undersampled</th>        <th class=\"col_heading level0 col2\" >Oversampled</th>    </tr>    <tr>        <th class=\"index_name level0\" >Seed</th>        <th class=\"index_name level1\" >Gender</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel0_row0\" class=\"row_heading level0 row0\" rowspan=2>865</th>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row0\" class=\"row_heading level1 row0\" >F</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow0_col0\" class=\"data row0 col0\" >81.9%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow0_col1\" class=\"data row0 col1\" >76.8%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow0_col2\" class=\"data row0 col2\" >76.8%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row1\" class=\"row_heading level1 row1\" >M</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow1_col0\" class=\"data row1 col0\" >80.0%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow1_col1\" class=\"data row1 col1\" >84.9%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow1_col2\" class=\"data row1 col2\" >84.9%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel0_row2\" class=\"row_heading level0 row2\" rowspan=2>888</th>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row2\" class=\"row_heading level1 row2\" >F</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow2_col0\" class=\"data row2 col0\" >80.1%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow2_col1\" class=\"data row2 col1\" >75.5%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow2_col2\" class=\"data row2 col2\" >75.5%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row3\" class=\"row_heading level1 row3\" >M</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow3_col0\" class=\"data row3 col0\" >78.6%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow3_col1\" class=\"data row3 col1\" >81.5%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow3_col2\" class=\"data row3 col2\" >81.5%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel0_row4\" class=\"row_heading level0 row4\" rowspan=2>616</th>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row4\" class=\"row_heading level1 row4\" >F</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow4_col0\" class=\"data row4 col0\" >79.6%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow4_col1\" class=\"data row4 col1\" >75.2%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow4_col2\" class=\"data row4 col2\" >75.2%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row5\" class=\"row_heading level1 row5\" >M</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow5_col0\" class=\"data row5 col0\" >78.5%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow5_col1\" class=\"data row5 col1\" >80.1%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow5_col2\" class=\"data row5 col2\" >80.1%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel0_row6\" class=\"row_heading level0 row6\" rowspan=2>171</th>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row6\" class=\"row_heading level1 row6\" >F</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow6_col0\" class=\"data row6 col0\" >82.9%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow6_col1\" class=\"data row6 col1\" >80.3%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow6_col2\" class=\"data row6 col2\" >80.3%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row7\" class=\"row_heading level1 row7\" >M</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow7_col0\" class=\"data row7 col0\" >74.2%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow7_col1\" class=\"data row7 col1\" >78.4%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow7_col2\" class=\"data row7 col2\" >78.4%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel0_row8\" class=\"row_heading level0 row8\" rowspan=2>163</th>\n",
       "                        <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row8\" class=\"row_heading level1 row8\" >F</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow8_col0\" class=\"data row8 col0\" >83.3%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow8_col1\" class=\"data row8 col1\" >80.9%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow8_col2\" class=\"data row8 col2\" >80.9%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                                <th id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8dlevel1_row9\" class=\"row_heading level1 row9\" >M</th>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow9_col0\" class=\"data row9 col0\" >80.7%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow9_col1\" class=\"data row9 col1\" >83.0%</td>\n",
       "                        <td id=\"T_685ccf51_bed3_11ea_8a52_9cebe8f2ef8drow9_col2\" class=\"data row9 col2\" >83.0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1c2cafd0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seeds = 5\n",
    "seeds = random.sample(range(0,1000),n_seeds)\n",
    "iterables = [seeds,['F','M']]\n",
    "index = pd.MultiIndex.from_product(iterables, names = ['Seed','Gender'])\n",
    "df = pd.DataFrame(np.zeros((n_seeds*2, 3)),index =index, columns = [\"Normal\",\"Undersampled\",\"Oversampled\"])\n",
    "counter = 0\n",
    "for seed in seeds:\n",
    "    random.seed(seed)\n",
    "    allNames = males + females\n",
    "    random.shuffle(allNames)\n",
    "    test_set, devtest_set, train_set, tsName, dtName, tName = tts(gender_features3, allNames)\n",
    "    for i in range(0,3):\n",
    "        train_set2 = []\n",
    "        tname = []\n",
    "        if i == 0:\n",
    "            train_set2 = train_set\n",
    "        elif i == 1:\n",
    "            train_set2, tName = balance_train(train_set, tName, 1)\n",
    "        elif i == 2:\n",
    "            train_set2, tName = balance_train(train_set, tName, 0)\n",
    "            \n",
    "        nbClass = nltk.NaiveBayesClassifier.train(train_set2)\n",
    "        tsPred, tsError = pred_calc(tsName, gender_features3,nbClass)\n",
    "        f_pct, m_pct = pull_correct(allNames, tsPred)\n",
    "        df.iloc[counter][i] = f_pct\n",
    "        df.iloc[counter+1][i] = m_pct\n",
    "    allNames =[]\n",
    "    counter = counter + 2\n",
    "    \n",
    "df.style.format({\n",
    "    'Normal': '{:,.1%}'.format,\n",
    "    'Undersampled': '{:,.1%}'.format,\n",
    "    'Oversampled': '{:,.1%}'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the table above our female name accuracy changes significantly even just for the Normal training set (ranging anywhere from below 80% to above 85%) depending on the random seed chosen to split the data into train and test datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our last step in this project is to create a Maximum Entropy Classifier for the data.\n",
    "\n",
    "The Maximum Entropy classifier model is a generalization of the model used by the Naive Bayes classifier. Like the Naive Bayes model, the Maximum Entropy classifier calculates the likelihood of each label for a given input value by multiplying together the parameters that are applicable for the input value and label.\n",
    "\n",
    "Let's calculate the entropy of the labels for our dataset. Higher entropy implies better classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951030970454714\n"
     ]
    }
   ],
   "source": [
    "# make a list of male and female\n",
    "all_male_female = list(repeat('male', len(males))) + list(repeat('female', len(females)))\n",
    "def entropy(labels):    \n",
    "    freq_dist = nltk.FreqDist(labels)    \n",
    "    probs = [freq_dist.freq(i) for i in nltk.FreqDist(labels)]    \n",
    "    return -sum([j * math.log(j,2) for j in probs])\n",
    "\n",
    "print (entropy(all_male_female))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above function shows that entropy is at 95%. <br> Let's create maximum entropy classifier model based on the features using training, dev test, and test sets. We will apply the model with 3 different feature sets i.e gender_features, gender_features2, and gender_features3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_1, devtest_set_1, train_set_1, tsName_1, dtName_1, tName_1 = tts(gender_features, allNames)\n",
    "test_set_2, devtest_set_2, train_set_2, tsName_2, dtName_2, tName_2 = tts(gender_features2, allNames)\n",
    "test_set_3, devtest_set_3, train_set_3, tsName_3, dtName_3, tName_3 = tts(gender_features3, allNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_1 = nltk.classify.MaxentClassifier.train(train_set_1)\n",
    "preds_1, errors_1 = pred_calc(dtName_1, gender_features, classifier_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_2 = nltk.classify.MaxentClassifier.train(train_set_2)\n",
    "preds_2, errors_2 = pred_calc(dtName_2, gender_features2, classifier_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "classifier_3 = nltk.classify.MaxentClassifier.train(train_set_3)\n",
    "preds_3, errors_3 = pred_calc(dtName_3, gender_features3, classifier_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets put all 3 features in a tablular format and see the accuracy of devtest_set and test_set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MODEL</th>\n",
       "      <th>DEV_ACCURACY</th>\n",
       "      <th>TEST_ACCURACY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Final</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MODEL  DEV_ACCURACY  TEST_ACCURACY\n",
       "0   First         0.806          0.772\n",
       "1  Second         0.798          0.828\n",
       "2   Final         0.812          0.830"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([['First', nltk.classify.accuracy(classifier_1, devtest_set_1), nltk.classify.accuracy(classifier_1, test_set_1)],\n",
    "             ['Second', nltk.classify.accuracy(classifier_2, devtest_set_2), nltk.classify.accuracy(classifier_2, test_set_2)], \n",
    "             ['Final', nltk.classify.accuracy(classifier_3, devtest_set_3), nltk.classify.accuracy(classifier_3, test_set_3)]],\n",
    "            columns = ['MODEL', 'DEV_ACCURACY', 'TEST_ACCURACY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our Max Entropy classifier uses an iterative method to maximize the performance of the training corpus classification. In this case the default number of iteration was 100. Due to this  it takes a long time to train a huge dataset and could also explain why it is not as popular. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we created a Naive Bayes Classifier to predict the gender of a given name from our Names corpus. With a robust corpus of 7944 names, we randomized and split the data into a test set of 500 names (for final testing of our model), a development test set of 500 names to utilize while tweaking and adjusting our model features, and a training set that we used throughout to train our model -- which contained 6944 names.\n",
    "\n",
    "##### Identifying the most informative features and creating our classifier\n",
    "\n",
    "After several runs of our Naive Bayes Classifier, we were able to pinpoint some of the most informative features:\n",
    "\n",
    "+ the value of the first and last few letters of a given name\n",
    "+ the number of vowels present in a given name\n",
    "+ the presence of double letters (i.e. \"ee\", \"oo\", etc.) in a given name\n",
    "+ the length of a given name\n",
    "+ the number of consonants in a given name\n",
    "+ and the presence of certain letters in a given name (based on research, some letters seemed to be present more frequently in male or female names)\n",
    "\n",
    "With our features identified, we were able to use our final classifier on our test set of 500 names. We found that our classifier, and these features were able to successfully predict the gender of about 80% of the names in our test corpus. \n",
    "\n",
    "##### Evaluating the performance of our classifier and resampling our training dataset\n",
    "\n",
    "Although this was interesting, we did realize that there was an unequal distribution of male and female names present in our Names corpus, and thus found that the prediction accuracy was slightly higher for females than for males in our final evaluation. We can attribute this to the fact that the model had more female names to train on, which ultimately led to a slightly better performance when we subjected it to our final test set.\n",
    "\n",
    "To investigate this further, we decided to retrain our model in two ways: \n",
    "\n",
    "1) We **undersampled the female names** in our training set in order to create a more equal proportion of female/male names for our classifier to determine patterns from -- to do this, we randomly removed about 2000 female names from our training data\n",
    "\n",
    "2) We **oversampled the male names** in our training set in order to match the number of female names -- to do this, we randomly copied about 2000 male names to match the number of female names present in the training data\n",
    "\n",
    "\n",
    "##### Summary of our findings\n",
    "\n",
    "After training our data with these new splits, we then subjected this new classifier on our test data and found that the overall performance decreased slightly (by about 1%). As we can see from the summary tables, both approaches to balancing the training dataset reduced the accuracy of predicting female names, but increased that of predicting male names. This was to be expected since the resampled training data and the corresponding algorithm had fewer female names to determine patterns from, leading to less accurate predictions. However, this in turn increased the relative impact of the male-predictor patterns.\n",
    "\n",
    "Overall, we were able to implement a Naive Bayes Classifier and Maximum Entropy Classifier on our names corpus, and after conducting a few different sampling techniques, we generated a classifier that preformed quite well (~80% accuracy predicting female and male names)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "1. D. M. Sidhu and P. M. Pexman. Whats in a name? sound symbolism and gender in first names. PLOS ONE, 10(5):e0126809, 2015.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
